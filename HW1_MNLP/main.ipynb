{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a481250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import networkx as nx\n",
    "import nest_asyncio\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from optuna.visualization import plot_param_importances, plot_contour\n",
    "import pandas as pd\n",
    "from plotly.graph_objects import Figure\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "import wandb\n",
    "\n",
    "from modules import dataset, graph, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330ae1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows for asyncio to be run in notebooks\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570449bf",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af026745",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f64494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "# Preprocessors\n",
    "scaler: StandardScaler = StandardScaler()\n",
    "label_encoder: LabelEncoder = LabelEncoder()\n",
    "\n",
    "# Prepare the training set\n",
    "train_set: pd.DataFrame = dataset.get_page_len_dataset('train')\n",
    "train_x: pd.DataFrame = train_set.drop(columns=['label'])\n",
    "train_x = pd.DataFrame(scaler.fit_transform(train_x), columns=train_x.columns)\n",
    "train_y: torch.Tensor = torch.tensor(label_encoder.fit_transform(train_set['label']))\n",
    "\n",
    "# Prepare the validation set\n",
    "valid_set: pd.DataFrame = dataset.get_page_len_dataset('valid')\n",
    "valid_x: pd.DataFrame = valid_set.drop(columns=['label']).reindex(columns=train_x.columns)\n",
    "valid_x: pd.DataFrame = pd.DataFrame(scaler.transform(valid_x), columns=valid_x.columns)\n",
    "valid_y: torch.Tensor = torch.tensor(label_encoder.transform(valid_set['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b629e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graphs\n",
    "\n",
    "# Parameters\n",
    "mode: Literal['iou', 'correlation'] = 'correlation'\n",
    "treshold: float = 0.5\n",
    "\n",
    "training_graphs: list[nx.Graph] = graph.get_similarity_graphs(train_x, similarity_threshold=treshold, mode=mode, show=True)\n",
    "validation_graphs: list[nx.Graph] = graph.get_similarity_graphs(valid_x, similarity_threshold=treshold, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2cc711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the graphs compatible with PyTorch Geometric\n",
    "\n",
    "train_data: list[Data] = []\n",
    "for graph, label in zip(training_graphs, train_y):\n",
    "    data: Data = from_networkx(graph)\n",
    "    data.y = label\n",
    "    train_data.append(data)\n",
    "\n",
    "valid_data: list[Data] = []\n",
    "for graph, label in zip(validation_graphs, valid_y):\n",
    "    data: Data = from_networkx(graph)\n",
    "    data.y = label\n",
    "    valid_data.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652f4f1",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b0ef91",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to optimize the hyperparameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Hyperparameters\n",
    "    batch_size: int = 2 ** trial.suggest_int('batch_size_exp', 4, 7)\n",
    "    hidden_dim: int = trial.suggest_int('hidden_dim', 16, 128, step = 16)\n",
    "    lr: float = trial.suggest_float('lr', 1e-5, 1e-1, log = True)\n",
    "    dropout: float = trial.suggest_float('dropout', 0., 0.5)\n",
    "    smoothing: float = trial.suggest_float('smoothing', 0., 0.4)\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader: DataLoader = DataLoader(train_data,\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle = True\n",
    "                                          )\n",
    "    valid_loader: DataLoader = DataLoader(valid_data,\n",
    "                                          batch_size = batch_size,\n",
    "                                          )\n",
    "\n",
    "    # Model\n",
    "    gcn: model.GCN = model.GCN(1, hidden_dim, lr = lr, dropout = dropout, smoothing = smoothing)\n",
    "\n",
    "    # Callbacks\n",
    "    early_stopping: EarlyStopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    pruning_callback: PyTorchLightningPruningCallback = PyTorchLightningPruningCallback(trial, monitor='val_loss')\n",
    "\n",
    "    # Trainer\n",
    "    trainer: pl.Trainer = pl.Trainer(callbacks = [early_stopping, pruning_callback],\n",
    "                                     logger = False,\n",
    "                                     enable_progress_bar = False,\n",
    "                                     enable_model_summary = False\n",
    "                                     )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(gcn, train_loader, valid_loader)\n",
    "\n",
    "    pruning_callback.check_pruned()\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss: float = trainer.validate(gcn, valid_loader, verbose=False)[0]['val_loss']\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f2f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna study\n",
    "study: optuna.Study = optuna.create_study(pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb58746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameter importances\n",
    "param_importances_fig: Figure = plot_param_importances(study)\n",
    "param_fig: Figure = plot_param_importances(study)\n",
    "param_fig.update_layout(autosize=False,\n",
    "                        width=1200,\n",
    "                        height=400\n",
    "                        )\n",
    "param_fig.show()\n",
    "\n",
    "# Plot contour\n",
    "contour_fig: Figure = plot_contour(study)\n",
    "contour_fig.update_layout(autosize=False,\n",
    "                          width=1200,\n",
    "                          height=1200\n",
    "                          )\n",
    "contour_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b2392f",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e263a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the best hyperparameters and print them\n",
    "best_params: dict[str, int|float] = study.best_trial.params\n",
    "\n",
    "# Retrain the model with the best hyperparameters\n",
    "best_batch_size: int = int(2 ** best_params['batch_size_exp'])\n",
    "best_hidden_dim: int = int(best_params['hidden_dim'])\n",
    "best_lr: float = best_params['lr']\n",
    "best_dropout: float = best_params['dropout']\n",
    "best_smoothing: float = best_params['smoothing']\n",
    "\n",
    "print(f\"Best hyperparameters:\\n\\tbatch_size: {best_batch_size}\\n\\thidden_dim: {best_hidden_dim}\\n\\tlr: {best_lr:.3e}\\n\\tdropout: {best_dropout:.3e}\\n\\tsmoothing: {best_smoothing:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43873c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with the best hyperparameters\n",
    "\n",
    "# Data loaders\n",
    "train_loader: DataLoader = DataLoader(train_data,\n",
    "                                      batch_size = best_batch_size,\n",
    "                                      shuffle = True\n",
    "                                      )\n",
    "valid_loader: DataLoader = DataLoader(valid_data,\n",
    "                                      batch_size = best_batch_size\n",
    "                                      )\n",
    "\n",
    "# Model\n",
    "gcn: model.GCN = model.GCN(1, best_hidden_dim, lr = best_lr, dropout = best_dropout, smoothing = best_smoothing)\n",
    "\n",
    "# Wandb logger\n",
    "wandb_logger: WandbLogger = WandbLogger(project='MNLP_HW_1', name='best_model', dir='wandb')\n",
    "\n",
    "# Callbacks\n",
    "checkpoint: ModelCheckpoint = ModelCheckpoint(monitor='val_loss', filename=f'best_model.ckpt')\n",
    "early_stopping: EarlyStopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Trainer\n",
    "trainer: pl.Trainer = pl.Trainer(callbacks = [early_stopping, checkpoint],\n",
    "                                 logger = wandb_logger,\n",
    "                                 log_every_n_steps = len(train_loader)\n",
    "                                 )\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(gcn, train_loader, valid_loader)\n",
    "\n",
    "# Close wandb and remove the logger from the trainer\n",
    "trainer.logger = None\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f03d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "gcn: model.GCN = model.GCN.load_from_checkpoint(checkpoint.best_model_path)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "trainer.validate(gcn, valid_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
