{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c94f1ed",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356cba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import networkx as nx\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from optuna.visualization import plot_param_importances, plot_contour\n",
    "import pandas as pd\n",
    "from pandas import Index\n",
    "from plotly.graph_objects import Figure\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "from modules import dataset, graph, models_creation, paths\n",
    "from modules.utils import model as model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330ae1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows for asyncio to be run in notebooks\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cff468",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc2262",
   "metadata": {},
   "source": [
    "### Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf157a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_set: pd.DataFrame = dataset.extract_dataset('train')\n",
    "val_set: pd.DataFrame = dataset.extract_dataset('validation')\n",
    "test_set: pd.DataFrame = dataset.extract_dataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47727c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split x and y\n",
    "train_x: pd.DataFrame = train_set.drop(columns = ['label'])\n",
    "train_y: pd.Series = train_set['label']\n",
    "val_x: pd.DataFrame = val_set.drop(columns = ['label'])\n",
    "val_y: pd.Series = val_set['label']\n",
    "test_x: pd.DataFrame = test_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154cd08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns that are not needed\n",
    "cols_to_drop: list[str] = train_set.filter(regex = '_extract$').columns.tolist()    # Used in the previous task\n",
    "cols_to_drop += ['item', 'name', 'description', 'category']\n",
    "train_x.drop(columns = cols_to_drop, inplace = True)\n",
    "val_x.drop(columns = cols_to_drop, inplace = True)\n",
    "test_x.drop(columns = cols_to_drop, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dff2ee2",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f64494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode categorical columns\n",
    "one_hot_encoder: OneHotEncoder = OneHotEncoder(sparse_output = False, handle_unknown = 'ignore')\n",
    "categorical_columns: Index = train_x.select_dtypes(exclude = 'number').columns\n",
    "one_hot_encoder.fit(train_x[categorical_columns])\n",
    "encoded_columns: NDArray[str] = one_hot_encoder.get_feature_names_out(categorical_columns)  # type: ignore\n",
    "train_x_encoded: pd.DataFrame = pd.DataFrame(one_hot_encoder.transform(train_x[categorical_columns]),   # type: ignore\n",
    "                                             columns = encoded_columns\n",
    "                                             )\n",
    "val_x_encoded: pd.DataFrame = pd.DataFrame(one_hot_encoder.transform(val_x[categorical_columns]),   # type: ignore\n",
    "                                           columns = encoded_columns\n",
    "                                           )\n",
    "test_x_encoded: pd.DataFrame = pd.DataFrame(one_hot_encoder.transform(test_x[categorical_columns]),   # type: ignore\n",
    "                                            columns = encoded_columns\n",
    "                                            )\n",
    "\n",
    "# Scale numerical columns\n",
    "scaler: MinMaxScaler = MinMaxScaler()\n",
    "numerical_columns: Index = train_x.select_dtypes(include = 'number').columns\n",
    "train_x_encoded[numerical_columns] = scaler.fit_transform(train_x[numerical_columns])\n",
    "val_x_encoded[numerical_columns] = scaler.transform(val_x[numerical_columns])\n",
    "test_x_encoded[numerical_columns] = scaler.transform(test_x[numerical_columns])\n",
    "\n",
    "# Encode labels\n",
    "label_encoder: LabelEncoder = LabelEncoder()\n",
    "train_y_encoded: torch.Tensor = torch.tensor(label_encoder.fit_transform(train_y))\n",
    "val_y_encoded: torch.Tensor = torch.tensor(label_encoder.transform(val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b71e1a",
   "metadata": {},
   "source": [
    "### Data Structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db79cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the similarity graph\n",
    "graph_creation_df: pd.DataFrame = train_x.filter(regex = '_length$')\n",
    "graph_creation_df = graph_creation_df.rename(columns = lambda x: x.replace('_length', ''))\n",
    "similarity_graph: graph.SimilarityGraph = graph.SimilarityGraph(graph_creation_df, threshold = 0.6, connected = True, show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60a6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Dataloaders\n",
    "\n",
    "def get_loader(x: pd.DataFrame, y: torch.Tensor|None, shuffle: bool = False) -> DataLoader:\n",
    "    \"\"\"\n",
    "    Get the DataLoader for the given data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split the different kinds of columns\n",
    "    global_columns: list[str] = encoded_columns.tolist() + ['sitelinks_count']\n",
    "\n",
    "    global_data: torch.Tensor = torch.from_numpy(x[global_columns].to_numpy(dtype = np.float32))\n",
    "    graphs: list[nx.Graph] = similarity_graph.get_graphs(x.drop(columns = global_columns))\n",
    "\n",
    "    # Create the DataLoader\n",
    "    data_list: list[Data] = []\n",
    "    for i in range(len(graphs)):\n",
    "        data: Data = from_networkx(graphs[i])\n",
    "        data.x_fc = global_data[i]\n",
    "        if y is not None:\n",
    "            data.y = y[i]\n",
    "        data_list.append(data)\n",
    "\n",
    "    return DataLoader(data_list, batch_size = 256, shuffle = shuffle)\n",
    "\n",
    "train_loader: DataLoader = get_loader(train_x_encoded, train_y_encoded, shuffle = True)\n",
    "val_loader: DataLoader = get_loader(val_x_encoded, val_y_encoded)\n",
    "test_loader: DataLoader = get_loader(test_x_encoded, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c94dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of features for the model\n",
    "\n",
    "n_global_features: int = train_loader.dataset[0].x_fc.shape[0]\n",
    "n_local_features: int = train_loader.dataset[0].x_graph.shape[1]\n",
    "n_classes: int = len(label_encoder.classes_)\n",
    "\n",
    "print(f\"Number of global features: {n_global_features}\")\n",
    "print(f\"Number features for each node: {n_local_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652f4f1",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b0ef91",
   "metadata": {},
   "source": [
    "### Tuning and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4621125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model obtained during hyperparameter tuning\n",
    "best_overall_checkpoint: ModelCheckpoint = ModelCheckpoint(monitor = 'val_f1', mode = 'max', dirpath = paths.GRAPH_MODEL_DIR, filename = 'graph_{epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to optimize the hyperparameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Hyperparameters\n",
    "    inner_dim: int = trial.suggest_int('inner_dim', 32, 256, log = True)\n",
    "    depth: int = trial.suggest_int('depth', 2, 5)\n",
    "    lr: float = trial.suggest_float('lr', 1e-5, 1e-2, log = True)\n",
    "\n",
    "    # Model\n",
    "    model: models_creation.GraphNet = models_creation.GraphNet(fc_features = n_global_features,\n",
    "                                                               node_features = n_local_features,\n",
    "                                                               n_classes = n_classes,\n",
    "                                                               inner_dim = inner_dim,\n",
    "                                                               depth = depth,\n",
    "                                                               lr = lr\n",
    "                                                               )\n",
    "\n",
    "    # Callbacks\n",
    "    early_stopping: EarlyStopping = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "    pruning_callback: PyTorchLightningPruningCallback = PyTorchLightningPruningCallback(trial, monitor = 'val_f1')\n",
    "\n",
    "    # Wandb logger\n",
    "    wandb_logger: WandbLogger = model_utils.configure_wandb_logger(project = 'Cultural classification on graphs', name = f'trial_{trial.number}')\n",
    "\n",
    "    # Trainer\n",
    "    trainer: pl.Trainer = pl.Trainer(max_epochs = -1,\n",
    "                                     callbacks = [early_stopping, pruning_callback, best_overall_checkpoint],\n",
    "                                     precision = '16-mixed',\n",
    "                                     logger = wandb_logger,\n",
    "                                     log_every_n_steps = len(train_loader),\n",
    "                                     enable_progress_bar = False,\n",
    "                                     enable_model_summary = False\n",
    "                                     )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    pruning_callback.check_pruned()\n",
    "\n",
    "    # Evaluate the model on the best epoch\n",
    "    f1: float\n",
    "    try:\n",
    "        f1 = wandb_logger.experiment.summary['val_f1']['max']\n",
    "    except:\n",
    "        raise optuna.TrialPruned(\"No f1 score found in wandb logger. Probably something went wrong during training.\")\n",
    "    finally:\n",
    "        # Close the wandb run\n",
    "        wandb_logger.experiment.finish()\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f2f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna study\n",
    "study: optuna.Study = optuna.create_study(direction = 'maximize', pruner = optuna.pruners.MedianPruner(n_startup_trials = 10, n_warmup_steps = 5))\n",
    "study.optimize(objective, n_trials = 50, show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the best model checkpoint\n",
    "best_model_path: Path = model_utils.rename_best_checkpoint(best_overall_checkpoint, study.best_trial.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb58746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameter importances\n",
    "param_importances_fig: Figure = plot_param_importances(study)\n",
    "param_fig: Figure = plot_param_importances(study)\n",
    "param_fig.update_layout(autosize = False,\n",
    "                        width = 1200,\n",
    "                        height = 400\n",
    "                        )\n",
    "param_fig.show()\n",
    "\n",
    "# Plot contour\n",
    "contour_fig: Figure = plot_contour(study)\n",
    "contour_fig.update_layout(autosize = False,\n",
    "                          width = 1200,\n",
    "                          height = 1200\n",
    "                          )\n",
    "contour_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters\n",
    "best_params: dict[str, int|float] = study.best_trial.params\n",
    "best_inner_dim: int = int(best_params['inner_dim'])\n",
    "best_depth: int = int(best_params['depth'])\n",
    "best_lr: float = best_params['lr']\n",
    "\n",
    "print(f\"\"\"Best hyperparameters:\n",
    "      \\tlayer dimension: {best_inner_dim}\n",
    "      \\tdepth: {best_depth}\n",
    "      \\tlearning rate: {best_lr:.3e}\"\"\"\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e7730",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002e4940",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba3c30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model: models_creation.GraphNet = models_creation.GraphNet.load_from_checkpoint(best_model_path)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "trainer: pl.Trainer = pl.Trainer(max_epochs = -1, precision = '16-mixed', logger = False)\n",
    "trainer.validate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa895d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "val_logits: torch.Tensor = torch.cat(trainer.predict(model, val_loader))    # type: ignore\n",
    "val_predictions_encoded: torch.Tensor = torch.argmax(val_logits, dim = 1)\n",
    "model_utils.plot_confusion_matrix(val_y_encoded, val_predictions_encoded, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcd25f5",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3b75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions for the test set\n",
    "test_logits: torch.Tensor = torch.cat(trainer.predict(model, test_loader))    # type: ignore\n",
    "test_predictions_encoded: torch.Tensor = torch.argmax(test_logits, dim = 1)\n",
    "test_predictions: NDArray[str] = label_encoder.inverse_transform(test_predictions_encoded)    # type: ignore\n",
    "\n",
    "# Save the predictions\n",
    "test_predictions_df: pd.DataFrame = pd.DataFrame({'item': test_set['item'], 'name': test_set['name'], 'label': test_predictions}, index = test_set.index)\n",
    "test_predictions_df.to_csv(paths.GRAPH_PREDICTIONS, index_label = 'id')\n",
    "print(f\"Saved the predictions on test set to {paths.GRAPH_PREDICTIONS}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
